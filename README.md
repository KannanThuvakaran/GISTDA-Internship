# GISTDA Internship
#### **Internship by GISTDA on 2024/06/04 - Present**

## Table of Contents

- **[Project Description](#project-description)**
- **[Literature Reading](#literature-reading)**

## Project Description

The project is about 

Good VLMs are produceds with a large dataset of image-text pairs. However in Remote Sensing, there is not enough image text pairs to create a good data set. (Many multitudes lower than usual)

In remote sensing, image-level classification assigns semantic labels like 'urban', 'forest', 'agricultural land' to images. However, complications arise when images contain multiple land cover types. This requires advanced techniques combining feature extraction and machine learning for accurate classification. 

#### Proposed Project
Recent research has demonstrated that fine-tuning large vision language models on small-scale, high-quality datasets can yield impressive performance in visual and language understanding.

- COGVLM TAKES Too much to fine tune

## Literature Reading
- Satellite Image Deep learning | [GitHub](https://github.com/satellite-image-deep-learning)
- Visual Language Models in Remote Sensing | [GitHub](https://github.com/lzw-lzw/awesome-remote-sensing-vision-language-models.git)
- SatGPT | [GitHub](https://github.com/lalligagger/satgpt.git) | [Website](https://satgpt.net/) 
- Segment-geospatial using SAM | [GitHub](https://github.com/opengeos/segment-geospatial.git) | [Website](https://samgeo.gishub.org/examples/text_prompts_batch/) | [YouTube](https://www.youtube.com/watch?v=cSDvuv1zRos&ab_channel=OpenGeospatialSolutions)
- Grounding DINO | [Website](https://huggingface.co/docs/transformers/en/model_doc/grounding-dino)
- GLIP |
- GLIP + SAM |

