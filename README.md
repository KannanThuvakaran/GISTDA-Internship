
# VLM for Remote Sensing
#### *GISTDA Internship by Kannan Thuvakaran* 

## Table of Contents

- **[1. Introduction](#1-introduction)**
- **[2. Literature Review](#literature-review)**
   - [2.1. Visual Language Models in Remote Sensing](#21-visual-language-models-in-remote-sensing--github)
   - [2.2. Satellite Image Deep Learning](#22-satellite-image-deep-learning--github)
   - [2.3. SatGPT](#23-satgpt--github--website)
- **[3. Complications of VLMs for Remote Sensing](#3-complications-with-vlms-for-remote-sensing)**
- **[4. Potential Solutions of VLM for Remote Sensing](#4-potential-solutions-with-vlms-for-remote-sensing)**


## 1. Introduction
#### 

## 2. Literature Review 

### 2.1. Visual Language Models in Remote Sensing | [GitHub](https://github.com/lzw-lzw/awesome-remote-sensing-vision-language-models.git)

### 2.2. Satellite Image Deep learning | [GitHub](https://github.com/satellite-image-deep-learning)

### 2.3 SatGPT | [GitHub](https://github.com/lalligagger/satgpt.git) | [Website](https://satgpt.net/) 
 GPT for satellite mission planning

## 3. Complications with VLMs for Remote Sensing

Good VLMs are produceds with a large dataset of image-text pairs. However in Remote Sensing, there is not enough image text pairs to create a good data set. (Many multitudes lower than usual)

In remote sensing, image-level classification assigns semantic labels like 'urban', 'forest', 'agricultural land' to images. However, complications arise when images contain multiple land cover types. This requires advanced techniques combining feature extraction and machine learning for accurate classification. 


## 4. Potential Solutions with VLMs for Remote Sensing

Recent research has demonstrated that fine-tuning large vision language models on small-scale, high-quality datasets can yield impressive performance in visual and language understanding.